import chromadb
from chromadb.config import Settings
from chromadb.utils import embedding_functions
from pathlib import Path
import uuid # For generating unique IDs for texts

# Assuming embedding_utils.py is in the same directory or accessible via PYTHONPATH
from .embedding_utils import generate_embedding, DEFAULT_EMBEDDING_MODEL, get_embedding_model

# Default path for ChromaDB persistence
DEFAULT_CHROMA_PATH = Path(__file__).resolve().parent.parent / "vectorstore"
# Default collection names
DEFAULT_DOC_COLLECTION_NAME = "jarvis_documents"
DEFAULT_CONVO_COLLECTION_NAME = "jarvis_conversations"

class VectorStore:
    """
    Manages vector storage and retrieval using ChromaDB for documents and conversation history.
    """

    def __init__(
        self,
        chroma_path: str | Path = DEFAULT_CHROMA_PATH,
        doc_collection_name: str = DEFAULT_DOC_COLLECTION_NAME,
        convo_collection_name: str = DEFAULT_CONVO_COLLECTION_NAME,
        embedding_model_name: str = DEFAULT_EMBEDDING_MODEL
    ):
        """
        Initializes the VectorStore, sets up ChromaDB client and collections.

        Args:
            chroma_path: Directory to store ChromaDB data.
            doc_collection_name: Name for the document collection.
            convo_collection_name: Name for the conversation history collection.
            embedding_model_name: Name of the sentence-transformer model to use.
        """
        self.chroma_path = str(chroma_path)
        self.doc_collection_name = doc_collection_name
        self.convo_collection_name = convo_collection_name
        self.embedding_model_name = embedding_model_name

        # Ensure the chroma_path directory exists
        Path(self.chroma_path).mkdir(parents=True, exist_ok=True)

        # Initialize SentenceTransformerEmbeddingFunction for ChromaDB
        # This allows Chroma to use our chosen sentence-transformer model directly.
        self.sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(
            model_name=self.embedding_model_name
        )

        try:
            self.client = chromadb.PersistentClient(
                path=self.chroma_path,
                settings=Settings(anonymized_telemetry=False) # Optional: disable telemetry
            )

            # Get or create collections using the embedding function
            self.doc_collection = self.client.get_or_create_collection(
                name=self.doc_collection_name,
                embedding_function=self.sentence_transformer_ef
            )
            self.convo_collection = self.client.get_or_create_collection(
                name=self.convo_collection_name,
                embedding_function=self.sentence_transformer_ef
            )
            print(f"ChromaDB client initialized. Document collection: '{self.doc_collection_name}'. Conversation collection: '{self.convo_collection_name}'.")

        except Exception as e:
            print(f"Error initializing ChromaDB client or collections: {e}")
            # Consider re-raising or custom exception handling
            raise

    def _add_texts_to_collection(
        self, 
        collection: chromadb.api.models.Collection.Collection, 
        texts: list[str], 
        metadatas: list[dict] | None = None, 
        ids: list[str] | None = None
    ) -> bool:
        """Helper to add texts to a specific Chroma collection."""
        if not texts:
            return False
        
        if ids is None:
            ids = [str(uuid.uuid4()) for _ in texts]
        elif len(ids) != len(texts):
            print("Error: Number of IDs must match number of texts.")
            return False

        if metadatas is not None and len(metadatas) != len(texts):
            print("Error: Number of metadatas must match number of texts if provided.")
            return False
        
        # ChromaDB with SentenceTransformerEmbeddingFunction handles embedding internally
        try:
            collection.add(
                documents=texts,
                metadatas=metadatas, # Can be None
                ids=ids
            )
            # print(f"Added {len(texts)} items to collection '{collection.name}'.")
            return True
        except Exception as e:
            print(f"Error adding texts to collection '{collection.name}': {e}")
            return False

    def add_documents(self, docs_texts: list[str], metadatas: list[dict] | None = None, ids: list[str] | None = None) -> bool:
        """
        Adds document texts to the document collection. Embeddings are generated by Chroma.

        Args:
            docs_texts: List of document texts to add.
            metadatas: Optional list of metadata dictionaries, one per document.
            ids: Optional list of unique IDs for each document text.

        Returns:
            True if successful, False otherwise.
        """
        return self._add_texts_to_collection(self.doc_collection, docs_texts, metadatas, ids)

    def add_conversation_history(self, convo_texts: list[str], metadatas: list[dict] | None = None, ids: list[str] | None = None) -> bool:
        """
        Adds conversation snippets to the conversation history collection.

        Args:
            convo_texts: List of conversation texts/snippets.
            metadatas: Optional list of metadata dictionaries.
            ids: Optional list of unique IDs.

        Returns:
            True if successful, False otherwise.
        """
        return self._add_texts_to_collection(self.convo_collection, convo_texts, metadatas, ids)

    def _query_collection(
        self, 
        collection: chromadb.api.models.Collection.Collection, 
        query_text: str,
        n_results: int = 5,
        where_filter: dict | None = None, # For metadata filtering
        include: list[str] | None = None # e.g., ["metadatas", "documents", "distances"]
    ) -> dict | None:
        """Helper to query a specific Chroma collection."""
        if not query_text:
            return None
        if include is None:
            include = ["metadatas", "documents", "distances"]
        
        try:
            # Query using the query_text directly. Chroma handles embedding it with the collection's EF.
            results = collection.query(
                query_texts=[query_text],
                n_results=n_results,
                where=where_filter, # e.g., {"source": "arxiv"}
                include=include
            )
            # print(f"Query to '{collection.name}' with '{query_text}' returned {len(results.get('ids', [[]])[0])} results.")
            return results
        except Exception as e:
            print(f"Error querying collection '{collection.name}': {e}")
            return None

    def query_documents(self, query_text: str, n_results: int = 5, where_filter: dict | None = None) -> dict | None:
        """
        Queries the document collection for relevant texts.

        Args:
            query_text: The query text to search for.
            n_results: Number of results to return.
            where_filter: Optional filter for metadata.

        Returns:
            A dictionary containing query results (documents, metadatas, distances), or None.
        """
        return self._query_collection(self.doc_collection, query_text, n_results, where_filter)

    def query_conversation_history(self, query_text: str, n_results: int = 3, where_filter: dict | None = None) -> dict | None:
        """
        Queries the conversation history collection.

        Args:
            query_text: The query text.
            n_results: Number of results.
            where_filter: Optional filter for metadata.

        Returns:
            A dictionary containing query results, or None.
        """
        return self._query_collection(self.convo_collection, query_text, n_results, where_filter)
    
    def get_document_collection_count(self) -> int:
        """Returns the number of items in the document collection."""
        return self.doc_collection.count()

    def get_conversation_collection_count(self) -> int:
        """Returns the number of items in the conversation collection."""
        return self.convo_collection.count()

    # Consider adding methods for deleting items, updating items, etc., if needed.
    # def delete_from_collection(collection, ids_to_delete)
    # def update_in_collection(...)

if __name__ == '__main__':
    print("Testing VectorStore...")

    # Ensure the test vectorstore directory is clean for a fresh test
    test_chroma_path = Path(__file__).resolve().parent.parent / "test_vectorstore"
    if test_chroma_path.exists():
        import shutil
        print(f"Cleaning up old test vectorstore at: {test_chroma_path}")
        shutil.rmtree(test_chroma_path) # Remove old directory
    test_chroma_path.mkdir(parents=True, exist_ok=True)

    # Initialize VectorStore for testing
    # Uses the default 'all-MiniLM-L6-v2' model from embedding_utils
    try:
        vector_store = VectorStore(
            chroma_path=test_chroma_path,
            doc_collection_name="test_docs",
            convo_collection_name="test_convos"
        )

        # Test adding documents
        print("\n--- Adding Documents ---")
        doc_texts = [
            "The history of artificial intelligence dates back to antiquity.",
            "Machine learning is a subfield of AI.",
            "Natural Language Processing enables computers to understand human language."
        ]
        doc_metadatas = [
            {"source": "wiki/AI_history", "topic": "history"},
            {"source": "textbook/ML_intro", "topic": "ML"},
            {"source": "article/NLP_overview", "topic": "NLP"}
        ]
        doc_ids = ["doc1", "doc2", "doc3"]
        print(f"Add documents: {vector_store.add_documents(doc_texts, doc_metadatas, doc_ids)}")
        print(f"Document collection count: {vector_store.get_document_collection_count()}") # Expected: 3

        # Test querying documents
        print("\n--- Querying Documents ---")
        query1 = "Tell me about AI history."
        results1 = vector_store.query_documents(query1, n_results=1)
        if results1 and results1.get('documents') and results1['documents'][0]:
            print(f"Query: '{query1}' -> Best match: '{results1['documents'][0][0]}' (meta: {results1['metadatas'][0][0]})")
        else:
            print(f"Query '{query1}' returned no results or unexpected format.")

        query2 = "What is NLP?"
        results2 = vector_store.query_documents(query2, n_results=1, where_filter={"topic": "NLP"})
        if results2 and results2.get('documents') and results2['documents'][0]:
            print(f"Query: '{query2}' (filtered) -> Best match: '{results2['documents'][0][0]}'")
        else:
            print(f"Query '{query2}' (filtered) returned no results or unexpected format.")

        # Test adding conversation history
        print("\n--- Adding Conversation History ---")
        convo_texts = [
            "User: Hello JARVIS. Agent: Hello! How can I help you today?",
            "User: What was our last topic? Agent: We were discussing vector databases.",
            "User: Remind me about ChromaDB. Agent: ChromaDB is an open-source embedding database."
        ]
        convo_metadatas = [
            {"timestamp": "2023-01-01T10:00:00Z", "user_id": "user123"},
            {"timestamp": "2023-01-01T10:05:00Z", "user_id": "user123"},
            {"timestamp": "2023-01-01T10:10:00Z", "user_id": "user123"}
        ]
        convo_ids = ["convo1", "convo2", "convo3"]
        print(f"Add conversation history: {vector_store.add_conversation_history(convo_texts, convo_metadatas, convo_ids)}")
        print(f"Conversation collection count: {vector_store.get_conversation_collection_count()}") # Expected: 3

        # Test querying conversation history
        print("\n--- Querying Conversation History ---")
        query_convo = "What did we talk about vector databases?"
        results_convo = vector_store.query_conversation_history(query_convo, n_results=1)
        if results_convo and results_convo.get('documents') and results_convo['documents'][0]:
            print(f"Query: '{query_convo}' -> Best match: '{results_convo['documents'][0][0]}'")
        else:
            print(f"Query '{query_convo}' returned no results or unexpected format.")

        print("\nVectorStore test complete.")

    except Exception as e:
        print(f"An error occurred during VectorStore testing: {e}")
    finally:
        # Clean up test vectorstore directory
        if test_chroma_path.exists():
            import shutil
            print(f"Cleaning up test vectorstore at: {test_chroma_path}")
            shutil.rmtree(test_chroma_path) 